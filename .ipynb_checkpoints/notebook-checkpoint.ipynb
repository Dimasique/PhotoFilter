{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4itFIDV_oEKF"
   },
   "source": [
    "This notebook provides an minimal working example of the sky augmentation in the preprint paper \"Castle in the Sky: Dynamic Sky Replacement and Harmonization in Videos, arXiv:2010.11800\"\n",
    "\n",
    "[Project Page](https://jiupinjia.github.io/skyar/) | [GitHub](https://github.com/jiupinjia/SkyAR) | [Preprint](https://arxiv.org/abs/2010.11800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-xQW_hCCpFw0"
   },
   "source": [
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png\" /></a><span xmlns:dct=\"http://purl.org/dc/terms/\" property=\"dct:title\">   The project </a> is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "XalDZNpvnDRD"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import argparse\n",
    "from networks import *\n",
    "from skyboxengine import *\n",
    "import utils\n",
    "import torch\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Decide which device we want to run on\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SKOmgkkRnREy"
   },
   "source": [
    "Download pretrained sky matting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "I669W3x7eLPJ"
   },
   "outputs": [],
   "source": [
    "# Define some helper functions for downloading pretrained model\n",
    "# taken from this StackOverflow answer: https://stackoverflow.com/a/39225039\n",
    "import requests\n",
    "\n",
    "def download_file_from_google_drive(id, destination):\n",
    "    URL = \"https://docs.google.com/uc?export=download\"\n",
    "\n",
    "    session = requests.Session()\n",
    "\n",
    "    response = session.get(URL, params = { 'id' : id }, stream = True)\n",
    "    token = get_confirm_token(response)\n",
    "\n",
    "    if token:\n",
    "        params = { 'id' : id, 'confirm' : token }\n",
    "        response = session.get(URL, params = params, stream = True)\n",
    "\n",
    "    save_response_content(response, destination)    \n",
    "\n",
    "def get_confirm_token(response):\n",
    "    for key, value in response.cookies.items():\n",
    "        if key.startswith('download_warning'):\n",
    "            return value\n",
    "\n",
    "    return None\n",
    "\n",
    "def save_response_content(response, destination):\n",
    "    CHUNK_SIZE = 32768\n",
    "\n",
    "    with open(destination, \"wb\") as f:\n",
    "        for chunk in response.iter_content(CHUNK_SIZE):\n",
    "            if chunk: # filter out keep-alive new chunks\n",
    "                f.write(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "AkPaMrzPBSO1"
   },
   "outputs": [],
   "source": [
    "# download and unzip...\n",
    "file_id = '1COMROzwR4R_7mym6DL9LXhHQlJmJaV0J'\n",
    "destination = './checkpoints_G_coord_resnet50.zip'\n",
    "download_file_from_google_drive(file_id, destination)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZUyCpseJpj5C"
   },
   "source": [
    "Config your model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "l62axCuysto0"
   },
   "outputs": [],
   "source": [
    "args = utils.parse_config(path_to_json='./config/my_config.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "yYGGahkCT1j8"
   },
   "outputs": [],
   "source": [
    "class PhotoFilter:\n",
    "  \n",
    "  def __init__(self, args):\n",
    "\n",
    "    self.ckptdir = args.ckptdir\n",
    "    self.output_dir = args.output_dir\n",
    "    self.in_size_w, self.in_size_h = args.in_size_w, args.in_size_h\n",
    "    self.out_size_w, self.out_size_h = args.out_size_w, args.out_size_h\n",
    "\n",
    "    self.skyboxengine = SkyBox(args)\n",
    "\n",
    "    self.net_G = define_G(netG=args.net_G).to(device)\n",
    "    self.load_model()\n",
    "\n",
    "    if os.path.exists(args.output_dir) is False:\n",
    "        os.mkdir(args.output_dir)\n",
    "\n",
    "\n",
    "  def load_model(self):\n",
    "        checkpoint = torch.load(os.path.join(self.ckptdir, 'best_ckpt.pt'), map_location='cpu')\n",
    "        self.net_G.load_state_dict(checkpoint['model_G_state_dict'])\n",
    "        self.net_G.to(device)\n",
    "        self.net_G.eval()\n",
    "\n",
    "\n",
    "  def synthesize(self, img_HD, img_HD_prev):\n",
    "\n",
    "        h, w, c = img_HD.shape\n",
    "\n",
    "        img = cv2.resize(img_HD, (self.in_size_w, self.in_size_h))\n",
    "\n",
    "        img = np.array(img, dtype=np.float32)\n",
    "        img = torch.tensor(img).permute([2, 0, 1]).unsqueeze(0)\n",
    "\n",
    "        \n",
    "        print(img.shape)\n",
    "        with torch.no_grad():\n",
    "            G_pred = self.net_G(img.to(device))\n",
    "            G_pred = torch.nn.functional.interpolate(G_pred, (h, w), mode='bicubic', align_corners=False)\n",
    "            G_pred = G_pred[0, :].permute([1, 2, 0])\n",
    "            G_pred = torch.cat([G_pred, G_pred, G_pred], dim=-1)\n",
    "            G_pred = np.array(G_pred.detach().cpu())\n",
    "            G_pred = np.clip(G_pred, a_max=1.0, a_min=0.0)\n",
    "\n",
    "        skymask = self.skyboxengine.skymask_refinement(G_pred, img_HD)\n",
    "        syneth = self.skyboxengine.skyblend(img_HD, img_HD_prev, skymask)\n",
    "\n",
    "        return syneth\n",
    "\n",
    "    \n",
    "\n",
    "  def cvtcolor_and_resize(self, img_HD):\n",
    "\n",
    "        img_HD = cv2.cvtColor(img_HD, cv2.COLOR_BGR2RGB)\n",
    "        img_HD = np.array(img_HD / 255., dtype=np.float32)\n",
    "        img_HD = cv2.resize(img_HD, (self.out_size_w, self.out_size_h))\n",
    "\n",
    "        return img_HD\n",
    "\n",
    "\n",
    "  def process_img(self, datadir, background='jupiter.jpg', name='edited'):\n",
    "\n",
    "        img = cv2.imread(datadir)\n",
    "        x, y, _ = img.shape\n",
    "        #self.skyboxengine.args.out_size_w = y\n",
    "        #self.skyboxengine.args.out_size_h = x\n",
    "        #self.out_size_w, self.out_size_h = y, x\n",
    "        self.skyboxengine.args.skybox = background\n",
    "\n",
    "        img_HD = self.cvtcolor_and_resize(img)\n",
    "        img_HD_prev = img_HD\n",
    "        \n",
    "        syneth = self.synthesize(img_HD, img_HD_prev)\n",
    "\n",
    "        img_res  = np.array(255.0 * syneth[:, :, ::-1], dtype=np.uint8)\n",
    "\n",
    "        #print(x, y, img_res.shape)\n",
    "        cv2.imwrite(self.output_dir + '/' + name + '.jpg', cv2.resize(img_res, (y, x)))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialize network with normal\n"
     ]
    }
   ],
   "source": [
    "pf = PhotoFilter(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2740,
     "status": "ok",
     "timestamp": 1608827801431,
     "user": {
      "displayName": "Дмитрий Кадомцев",
      "photoUrl": "",
      "userId": "05360575676513867089"
     },
     "user_tz": -240
    },
    "id": "fyhwUz5-ZD2A",
    "outputId": "fdc6e648-a7cd-48a7-9563-110c6c05b0d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 384, 384])\n",
      "initialize skybox...\n"
     ]
    }
   ],
   "source": [
    "pf.process_img(\"./photos/2.jpg\", name='2', background='jupiter.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.skybox = \"jupiter.jpg\"\n",
    "pf.process_img(\"./photos/3.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import onnx\n",
    "from onnx_tf.backend import prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialize network with normal\n"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load(os.path.join(\"./checkpoints_G_coord_resnet50\", 'best_ckpt.pt'), map_location='cpu')\n",
    "\n",
    "net = define_G(netG=args.net_G).to(device)\n",
    "net.load_state_dict(checkpoint['model_G_state_dict'])\n",
    "\n",
    "    \n",
    "dummy_input = torch.rand(1, 3, 384, 384)\n",
    "\n",
    "torch.onnx.export(net,               # model being run\n",
    "                  dummy_input,                         # model input (or a tuple for multiple inputs)\n",
    "                  './model.onnx',            # where to save the model (can be a file or file-like object)\n",
    "                  export_params=True,        # store the trained parameter weights inside the model file\n",
    "                  opset_version=11,          # the ONNX version to export the model to\n",
    "                  do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "                  input_names = ['input'],   # the model's input names\n",
    "                  output_names = ['output'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_model = onnx.load('./model.onnx')\n",
    "\n",
    "\n",
    "onnx.checker.check_model(onnx_model)\n",
    "\n",
    "\n",
    "\n",
    "# Export model as .pb file\n",
    "#tf_rep.export_graph('./model.pb')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Копия блокнота \"photofilter.ipynb\"\"",
   "provenance": [
    {
     "file_id": "14JX8VYvf1OfxTBhq8ZEsfqsn6STr__eA",
     "timestamp": 1608842678754
    },
    {
     "file_id": "1-BqXD3EzDY6PHRdwb3cWayk2KictbFaz",
     "timestamp": 1608828239824
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
